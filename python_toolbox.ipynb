{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.read_csv('https://assets.datacamp.com/production/repositories/464/datasets/82e9842c09ad135584521e293091c2327251121d/tweets.csv')\n",
    "worldBank =pd.read_csv('https://assets.datacamp.com/production/repositories/464/datasets/2175fef4b3691db03449bbc7ddffb740319c1131/world_ind_pop_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataanalysisvisualization\n",
      "3\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "object1 = \"data\" + \"analysis\" + \"visualization\"\n",
    "object2 = 1 * 3\n",
    "object3 = \"1\" * 3\n",
    "print(object1)\n",
    "print(object2)\n",
    "print(object3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "# Define the function shout\n",
    "def shout():\n",
    "    \"\"\"Print a string with three exclamation marks\"\"\"\n",
    "    # Concatenate the strings: shout_word\n",
    "    shout_word = 'congratulations' + '!!!'\n",
    "\n",
    "    # Print shout_word\n",
    "    print(shout_word)\n",
    "\n",
    "# Call shout\n",
    "shout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout with the parameter, word\n",
    "def shout(word):\n",
    "    \"\"\"Print a string with three exclamation marks\"\"\"\n",
    "    # Concatenate the strings: shout_word\n",
    "    shout_word = word + '!!!'\n",
    "\n",
    "    # Print shout_word\n",
    "    print(shout_word)\n",
    "\n",
    "# Call shout with the string 'congratulations'\n",
    "shout('congratulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "#Define shout with the parameter, word\n",
    "\n",
    "def shout(word):\n",
    "    \"\"\"Return a string with three exclamation marks\"\"\"\n",
    "\n",
    "    # Concatenate the strings: shout_word\n",
    "    shout_word = word + '!!!'\n",
    "\n",
    "    # Replace print with return\n",
    "    return shout_word\n",
    "\n",
    "# Pass 'congratulations' to shout: yell\n",
    "yell = shout('congratulations')\n",
    "\n",
    "# Print yell\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shout with parameters word1 and word2\n",
    "def shout(word1, word2):\n",
    "    \"\"\"Concatenate strings with three exclamation marks\"\"\"\n",
    "    # Concatenate word1 with '!!!': shout1\n",
    "    shout1 = word1 + '!!!'\n",
    "    \n",
    "    # Concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + '!!!'\n",
    "    \n",
    "    # Concatenate shout1 with shout2: new_shout\n",
    "    new_shout = shout1 + shout2\n",
    "\n",
    "    # Return new_shout\n",
    "    return new_shout\n",
    "\n",
    "# Pass 'congratulations' and 'you' to shout(): yell\n",
    "yell = shout('congratulations', 'you')\n",
    "\n",
    "# Print yell\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n",
      "you!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout_all with parameters word1 and word2\n",
    "def shout_all(word1, word2):\n",
    "    \n",
    "    # Concatenate word1 with '!!!': shout1\n",
    "    shout1 = word1 + '!!!'\n",
    "    \n",
    "    # Concatenate word2 with '!!!': shout2\n",
    "    shout2 = word2 + '!!!'\n",
    "    \n",
    "    # Construct a tuple with shout1 and shout2: shout_words\n",
    "    shout_words = (shout1, shout2)\n",
    "\n",
    "    # Return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# Pass 'congratulations' and 'you' to shout_all(): yell1, yell2\n",
    "\n",
    "yell1, yell2 = shout_all('congratulations','you')\n",
    "\n",
    "# Print yell1 and yell2\n",
    "print(yell1)\n",
    "print(yell2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import Twitter data as DataFrame: df\n",
    "tweets_df = pd.read_csv('tweets.csv')\n",
    "\n",
    "# Initialize an empty dictionary: langs_count\n",
    "langs_count = {}\n",
    "\n",
    "# Extract column from DataFrame: col\n",
    "col = tweets_df['lang']\n",
    "\n",
    "# Iterate over lang column in DataFrame\n",
    "for entry in col:\n",
    "\n",
    "    # If the language is in langs_count, add 1 \n",
    "    if entry in langs_count.keys():\n",
    "        langs_count[entry] = langs_count[entry]+1\n",
    "    # Else add the language to langs_count, set the value to 1\n",
    "    else:\n",
    "        langs_count[entry] = 1\n",
    "\n",
    "# Print the populated dictionary\n",
    "print(langs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name):\n",
    "    \"\"\"Return a dictionary with counts of \n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: langs_count\n",
    "    langs_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = tweets_df[col_name]\n",
    "    \n",
    "    # Iterate over lang column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If the language is in langs_count, add 1\n",
    "        if entry in langs_count.keys():\n",
    "            langs_count[entry] += 1\n",
    "        # Else add the language to langs_count, set the value to 1\n",
    "        else:\n",
    "            langs_count[entry] = 1\n",
    "\n",
    "    # Return the langs_count dictionary\n",
    "    return langs_count\n",
    "\n",
    "# Call count_entries(): result\n",
    "result = count_entries(tweets_df,'lang')\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5\n",
    "\n",
    "def func1():\n",
    "    num = 3\n",
    "    print(num)\n",
    "\n",
    "def func2():\n",
    "    global num\n",
    "    double_num = num * 2\n",
    "    num = 6\n",
    "    print(double_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teen titans\n",
      "justice league\n"
     ]
    }
   ],
   "source": [
    "# Create a string: team\n",
    "team = \"teen titans\"\n",
    "\n",
    "# Define change_team()\n",
    "def change_team():\n",
    "    \"\"\"Change the value of the global variable team.\"\"\"\n",
    "\n",
    "    # Use team in global scope\n",
    "    global team\n",
    "\n",
    "    # Change the value of team in global: team\n",
    "    team = \"justice league\"\n",
    "# Print team\n",
    "print(team)\n",
    "\n",
    "# Call change_team()\n",
    "change_team()\n",
    "\n",
    "# Print team\n",
    "print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArithmeticError',\n",
       " 'AssertionError',\n",
       " 'AttributeError',\n",
       " 'BaseException',\n",
       " 'BlockingIOError',\n",
       " 'BrokenPipeError',\n",
       " 'BufferError',\n",
       " 'BytesWarning',\n",
       " 'ChildProcessError',\n",
       " 'ConnectionAbortedError',\n",
       " 'ConnectionError',\n",
       " 'ConnectionRefusedError',\n",
       " 'ConnectionResetError',\n",
       " 'DeprecationWarning',\n",
       " 'EOFError',\n",
       " 'Ellipsis',\n",
       " 'EncodingWarning',\n",
       " 'EnvironmentError',\n",
       " 'Exception',\n",
       " 'False',\n",
       " 'FileExistsError',\n",
       " 'FileNotFoundError',\n",
       " 'FloatingPointError',\n",
       " 'FutureWarning',\n",
       " 'GeneratorExit',\n",
       " 'IOError',\n",
       " 'ImportError',\n",
       " 'ImportWarning',\n",
       " 'IndentationError',\n",
       " 'IndexError',\n",
       " 'InterruptedError',\n",
       " 'IsADirectoryError',\n",
       " 'KeyError',\n",
       " 'KeyboardInterrupt',\n",
       " 'LookupError',\n",
       " 'MemoryError',\n",
       " 'ModuleNotFoundError',\n",
       " 'NameError',\n",
       " 'None',\n",
       " 'NotADirectoryError',\n",
       " 'NotImplemented',\n",
       " 'NotImplementedError',\n",
       " 'OSError',\n",
       " 'OverflowError',\n",
       " 'PendingDeprecationWarning',\n",
       " 'PermissionError',\n",
       " 'ProcessLookupError',\n",
       " 'RecursionError',\n",
       " 'ReferenceError',\n",
       " 'ResourceWarning',\n",
       " 'RuntimeError',\n",
       " 'RuntimeWarning',\n",
       " 'StopAsyncIteration',\n",
       " 'StopIteration',\n",
       " 'SyntaxError',\n",
       " 'SyntaxWarning',\n",
       " 'SystemError',\n",
       " 'SystemExit',\n",
       " 'TabError',\n",
       " 'TimeoutError',\n",
       " 'True',\n",
       " 'TypeError',\n",
       " 'UnboundLocalError',\n",
       " 'UnicodeDecodeError',\n",
       " 'UnicodeEncodeError',\n",
       " 'UnicodeError',\n",
       " 'UnicodeTranslateError',\n",
       " 'UnicodeWarning',\n",
       " 'UserWarning',\n",
       " 'ValueError',\n",
       " 'Warning',\n",
       " 'WindowsError',\n",
       " 'ZeroDivisionError',\n",
       " '__IPYTHON__',\n",
       " '__build_class__',\n",
       " '__debug__',\n",
       " '__doc__',\n",
       " '__import__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'abs',\n",
       " 'aiter',\n",
       " 'all',\n",
       " 'anext',\n",
       " 'any',\n",
       " 'ascii',\n",
       " 'bin',\n",
       " 'bool',\n",
       " 'breakpoint',\n",
       " 'bytearray',\n",
       " 'bytes',\n",
       " 'callable',\n",
       " 'chr',\n",
       " 'classmethod',\n",
       " 'compile',\n",
       " 'complex',\n",
       " 'copyright',\n",
       " 'credits',\n",
       " 'delattr',\n",
       " 'dict',\n",
       " 'dir',\n",
       " 'display',\n",
       " 'divmod',\n",
       " 'enumerate',\n",
       " 'eval',\n",
       " 'exec',\n",
       " 'execfile',\n",
       " 'filter',\n",
       " 'float',\n",
       " 'format',\n",
       " 'frozenset',\n",
       " 'get_ipython',\n",
       " 'getattr',\n",
       " 'globals',\n",
       " 'hasattr',\n",
       " 'hash',\n",
       " 'help',\n",
       " 'hex',\n",
       " 'id',\n",
       " 'input',\n",
       " 'int',\n",
       " 'isinstance',\n",
       " 'issubclass',\n",
       " 'iter',\n",
       " 'len',\n",
       " 'license',\n",
       " 'list',\n",
       " 'locals',\n",
       " 'map',\n",
       " 'max',\n",
       " 'memoryview',\n",
       " 'min',\n",
       " 'next',\n",
       " 'object',\n",
       " 'oct',\n",
       " 'open',\n",
       " 'ord',\n",
       " 'pow',\n",
       " 'print',\n",
       " 'property',\n",
       " 'range',\n",
       " 'repr',\n",
       " 'reversed',\n",
       " 'round',\n",
       " 'runfile',\n",
       " 'set',\n",
       " 'setattr',\n",
       " 'slice',\n",
       " 'sorted',\n",
       " 'staticmethod',\n",
       " 'str',\n",
       " 'sum',\n",
       " 'super',\n",
       " 'tuple',\n",
       " 'type',\n",
       " 'vars',\n",
       " 'zip']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import builtins\n",
    "dir(builtins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a!!!', 'b!!!', 'c!!!')\n"
     ]
    }
   ],
   "source": [
    "# Define three_shouts\n",
    "def three_shouts(word1, word2, word3):\n",
    "    \"\"\"Returns a tuple of strings\n",
    "    concatenated with '!!!'.\"\"\"\n",
    "\n",
    "    # Define inner\n",
    "    def inner(word):\n",
    "        \"\"\"Returns a string concatenated with '!!!'.\"\"\"\n",
    "        return word + '!!!'\n",
    "\n",
    "    # Return a tuple of strings\n",
    "    return (inner(word1), inner(word2), inner(word3))\n",
    "\n",
    "# Call three_shouts() and print\n",
    "print(three_shouts('a', 'b', 'c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello hellohellohello\n"
     ]
    }
   ],
   "source": [
    "# Define echo\n",
    "def echo(n):\n",
    "    \"\"\"Return the inner_echo function.\"\"\"\n",
    "\n",
    "    # Define inner_echo\n",
    "    def inner_echo(word1):\n",
    "        \"\"\"Concatenate n copies of word1.\"\"\"\n",
    "        echo_word = word1 * n\n",
    "        return echo_word\n",
    "\n",
    "    # Return inner_echo\n",
    "    return inner_echo\n",
    "\n",
    "# Call echo: twice\n",
    "twice = echo(2)\n",
    "\n",
    "# Call echo: thrice\n",
    "thrice = echo(3)\n",
    "\n",
    "# Call twice() and thrice() then print\n",
    "print(twice('hello'), thrice('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellohello\n",
      "hellohello!!!\n"
     ]
    }
   ],
   "source": [
    "# Define echo_shout()\n",
    "def echo_shout(word):\n",
    "    \"\"\"Change the value of a nonlocal variable\"\"\"\n",
    "    \n",
    "    # Concatenate word with itself: echo_word\n",
    "    echo_word = word + word\n",
    "    \n",
    "    # Print echo_word\n",
    "    print(echo_word)\n",
    "    \n",
    "    # Define inner function shout()\n",
    "    def shout():\n",
    "        \"\"\"Alter a variable in the enclosing scope\"\"\"    \n",
    "        # Use echo_word in nonlocal scope\n",
    "        nonlocal echo_word\n",
    "        \n",
    "        # Change echo_word to echo_word concatenated with '!!!'\n",
    "        echo_word = echo_word + '!!!'\n",
    "    \n",
    "    # Call function shout()\n",
    "    shout()\n",
    "    \n",
    "    # Print echo_word\n",
    "    print(echo_word)\n",
    "\n",
    "# Call function echo_shout() with argument 'hello'\n",
    "echo_shout('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions with a default argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey!!!\n",
      "HeyHeyHeyHeyHey!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "     exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = echo * word1\n",
    "\n",
    "    # Concatenate '!!!' to echo_word: shout_word\n",
    "    shout_word = echo_word + '!!!'\n",
    "\n",
    "    # Return shout_word\n",
    "    return shout_word\n",
    "\n",
    "# Call shout_echo() with \"Hey\": no_echo\n",
    "no_echo = shout_echo(\"Hey\")\n",
    "\n",
    "# Call shout_echo() with \"Hey\" and echo=5: with_echo\n",
    "with_echo = shout_echo(\"Hey\", echo=5)\n",
    "\n",
    "# Print no_echo and with_echo\n",
    "print(no_echo)\n",
    "print(with_echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEYHEYHEYHEYHEY!!!\n",
      "HEY!!!\n"
     ]
    }
   ],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1, intense= False):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1 * echo\n",
    "\n",
    "    # Make echo_word uppercase if intense is True\n",
    "    if intense is True:\n",
    "        # Make uppercase and concatenate '!!!': echo_word_new\n",
    "        echo_word_new = echo_word.upper() + '!!!'\n",
    "    else:\n",
    "        # Concatenate '!!!' to echo_word: echo_word_new\n",
    "        echo_word_new = echo_word + '!!!'\n",
    "\n",
    "    # Return echo_word_new\n",
    "    return echo_word_new\n",
    "\n",
    "# Call shout_echo() with \"Hey\", echo=5 and intense=True: with_big_echo\n",
    "with_big_echo = shout_echo(\"Hey\", echo=5, intense=True)\n",
    "\n",
    "# Call shout_echo() with \"Hey\" and intense=True: big_no_echo\n",
    "big_no_echo = shout_echo(\"Hey\",intense=True)\n",
    "\n",
    "# Print values\n",
    "print(with_big_echo)\n",
    "print(big_no_echo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions with variable-length arguments (*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luke\n",
      "lukeleiahanobidarth\n"
     ]
    }
   ],
   "source": [
    "# Define gibberish\n",
    "def gibberish(*args):\n",
    "    \"\"\"Concatenate strings in *args together.\"\"\"\n",
    "\n",
    "    # Initialize an empty string: hodgepodge\n",
    "    hodgepodge = ''\n",
    "\n",
    "    # Concatenate the strings in args\n",
    "    for word in args:\n",
    "        hodgepodge += word\n",
    "\n",
    "    # Return hodgepodge\n",
    "    return hodgepodge\n",
    "\n",
    "# Call gibberish() with one string: one_word\n",
    "one_word = gibberish('luke')\n",
    "\n",
    "# Call gibberish() with five strings: many_words\n",
    "many_words = gibberish(\"luke\", \"leia\", \"han\", \"obi\", \"darth\")\n",
    "\n",
    "# Print one_word and many_words\n",
    "print(one_word)\n",
    "print(many_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions with variable-length keyword arguments (**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: luke\n",
      "affiliation: jedi\n",
      "status: missing\n",
      "\n",
      "END REPORT\n",
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: anakin\n",
      "affiliation: sith lord\n",
      "status: deceased\n",
      "\n",
      "END REPORT\n"
     ]
    }
   ],
   "source": [
    "# Define report_status\n",
    "def report_status(**kwargs):\n",
    "    \"\"\"Print out the status of a movie character.\"\"\"\n",
    "\n",
    "    print(\"\\nBEGIN: REPORT\\n\")\n",
    "\n",
    "    # Iterate over the key-value pairs of kwargs\n",
    "    for key, value in kwargs.items():\n",
    "        # Print out the keys and values, separated by a colon ':'\n",
    "        print(key + \": \" + value)\n",
    "\n",
    "    print(\"\\nEND REPORT\")\n",
    "\n",
    "# First call to report_status()\n",
    "report_status(name=\"luke\", affiliation=\"jedi\", status=\"missing\")\n",
    "\n",
    "# Second call to report_status()\n",
    "report_status(name=\"anakin\", affiliation=\"sith lord\" , status=\"deceased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n",
      "{'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "\n",
    "    # Extract column from DataFrame: col\n",
    "    col = tweets_df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If entry is in cols_count, add 1\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "\n",
    "        # Else add the entry to cols_count, set the value to 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "\n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df)\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, 'source')\n",
    "\n",
    "# Print result1 and result2\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing arbitrary arguments to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n",
      "{'en': 97, 'et': 1, 'und': 2, '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, *args):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    #Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Iterate over column names in args\n",
    "    for col_name in args:\n",
    "    \n",
    "        # Extract column from DataFrame: col\n",
    "        col = tweets_df[col_name]\n",
    "    \n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in col:\n",
    "    \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "    \n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "\n",
    "    # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Call count_entries(): result2\n",
    "result2 = count_entries(tweets_df, 'lang', 'source')\n",
    "\n",
    "# Print result1 and result2\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello!!!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#varible_name = (lambda arg: code) \n",
    "add_bangs = (lambda a: a + '!!!')\n",
    "add_bangs('hello')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heyheyheyheyhey\n"
     ]
    }
   ],
   "source": [
    "#converting this function into a lambda function\n",
    "def echo_word(word1, echo):\n",
    "    \"\"\"Concatenate echo copies of word1.\"\"\"\n",
    "    words = word1 * echo\n",
    "    return words\n",
    "\n",
    "# Define echo_word as a lambda function: echo_word\n",
    "echo_word = (lambda word1, echo: word1*echo)\n",
    "\n",
    "# Call echo_word: result\n",
    "result = echo_word('hey',5)\n",
    "\n",
    "# Print result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map() and lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protego!!!', 'accio!!!', 'expecto patronum!!!', 'legilimens!!!']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: spells\n",
    "spells = [\"protego\", \"accio\", \"expecto patronum\", \"legilimens\"]\n",
    "\n",
    "# Use map() to apply a lambda function over spells: shout_spells\n",
    "shout_spells = map(lambda item: item + '!!!', spells)\n",
    "\n",
    "# Convert shout_spells to a list: shout_spells_list\n",
    "shout_spells_list = list(shout_spells)\n",
    "\n",
    "# Print the result\n",
    "print(shout_spells_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter() and lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'boromir', 'legolas', 'gandalf']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'pippin', 'aragorn', 'boromir', 'legolas', 'gimli', 'gandalf']\n",
    "\n",
    "# Use filter() to apply a lambda function over fellowship: result\n",
    "result = filter(lambda member: len(member) > 6 , fellowship)\n",
    "\n",
    "# Convert result to a list: result_list\n",
    "result_list= list(result)\n",
    "\n",
    "# Print result_list\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce() and lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robbsansaaryabrandonrickon\n"
     ]
    }
   ],
   "source": [
    "# Import reduce from functools\n",
    "from functools import reduce \n",
    "\n",
    "# Create a list of strings: stark\n",
    "stark = ['robb', 'sansa', 'arya', 'brandon', 'rickon']\n",
    "\n",
    "# Use reduce() to apply a lambda function over stark: result\n",
    "result = reduce(lambda item1, item2: item1+item2 ,stark)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error handling with try-except"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1 must be a string and echo must be an integer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=1):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Initialize empty strings: echo_word, shout_words\n",
    "    echo_word = ''\n",
    "    shout_words = ''\n",
    "    \n",
    "\n",
    "    # Add exception handling with try-except\n",
    "    try:\n",
    "        # Concatenate echo copies of word1 using *: echo_word\n",
    "        echo_word = word1*echo\n",
    "\n",
    "        # Concatenate '!!!' to echo_word: shout_words\n",
    "        shout_words = echo_word + '!!!'\n",
    "    except:\n",
    "        # Print error message\n",
    "        print(\"word1 must be a string and echo must be an integer.\")\n",
    "\n",
    "    # Return shout_words\n",
    "    return shout_words\n",
    "\n",
    "# Call shout_echo\n",
    "shout_echo(\"particle\", echo=\"accelerator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'particle!!!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define shout_echo\n",
    "def shout_echo(word1, echo=0):\n",
    "    \"\"\"Concatenate echo copies of word1 and three\n",
    "    exclamation marks at the end of the string.\"\"\"\n",
    "\n",
    "    # Raise an error with raise\n",
    "    if echo < 0:\n",
    "        raise ValueError('echo must be greater than or equal to 0') # can put Exception here as well.\n",
    "\n",
    "    # Concatenate echo copies of word1 using *: echo_word\n",
    "    echo_word = word1 * echo\n",
    "\n",
    "    # Concatenate '!!!' to echo_word: shout_word\n",
    "    shout_word = echo_word + '!!!'\n",
    "\n",
    "    # Return shout_word\n",
    "    return shout_word\n",
    "\n",
    "# Call shout_echo\n",
    "shout_echo(\"particle\", echo=1) #can change the value to raise the exception or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @bpolitics: .@krollbondrating's Christopher Whalen says Clinton is the weakest Dem candidate in 50 years https://t.co/pLk7rvoRSn https:/â€¦\n",
      "RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3\n",
      "RT @AlanLohner: The anti-American D.C. elites despise Trump for his America-first foreign policy. Trump threatens their gravy train. https:â€¦\n",
      "RT @BIackPplTweets: Young Donald trump meets his neighbor  https://t.co/RFlu17Z1eE\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @HouseCracka: 29,000+ PEOPLE WATCHING TRUMP LIVE ON ONE STREAM!!!\n",
      "\n",
      "https://t.co/7QCFz9ehNe\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  httpsâ€¦\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/â€¦\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  httpsâ€¦\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearlyâ€¦\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET httpsâ€¦\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/â€¦\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://â€¦\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET httpsâ€¦\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://â€¦\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearlyâ€¦\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9Nâ€¦\n",
      "RT @Norsu2: Nightmare WI poll for Ted Cruz has Kasich surging: Trump 29, Kasich 27, Cruz 25. https://t.co/lJsgbLYY1P #NeverTrump\n",
      "RT @thehill: WATCH: Protester pepper-sprayed point blank at Trump rally https://t.co/B5f65Al9ld https://t.co/skAfByXuQc\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9Nâ€¦\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/â€¦\n",
      "RT @DebbieStout5: Wow! Last I checked it was just 12 points &amp; that wasn't more than a day ago. Oh boy Trump ppl might want to rethinkðŸ¤” httpâ€¦\n",
      "RT @tyleroakley: i'm a messy bitch, but at least i'm not voting for trump\n",
      "RT @vandives: Trump supporters r tired of justice NOT being served. There's no justice anymore. Hardworking Americans get screwed. That's nâ€¦\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNNâ€¦\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will nâ€¦\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNNâ€¦\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:â€¦\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will nâ€¦\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:â€¦\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation Pâ€¦\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educatâ€¦\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation Pâ€¦\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educatâ€¦\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @Tâ€¦\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/â€¦\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didnâ€™t come out of nowhere.\" â€”Hillary\n",
      "httpsâ€¦\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @Tâ€¦\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didnâ€™t come out of nowhere.\" â€”Hillary\n",
      "httpsâ€¦\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/â€¦\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating tâ€¦\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating tâ€¦\n",
      "RT @GlendaJazzey: Donald Trumpâ€™s Campaign Financing Dodge, @rrotunda https://t.co/L8flI4lswG via @VerdictJustia\n",
      "RT @TUSK81: LOUDER FOR THE PEOPLE IN THE BACK https://t.co/hlPVyNLXzx\n",
      "RT @loopzoop: Well...put it back https://t.co/8Yb7BDT5VM\n",
      "RT @claytoncubitt: Stop asking Bernie supporters if theyâ€™ll vote for Hillary against Trump. We got a plan to beat Trump already. Called Berâ€¦\n",
      "RT @akaMaude13: Seriously can't make this up. What a joke. #NeverTrump  https://t.co/JkTx6mdRgC\n"
     ]
    }
   ],
   "source": [
    "# Select retweets from the Twitter DataFrame: result\n",
    "result = filter(lambda x: x[0:2] == 'RT' , tweets_df['text'])\n",
    "\n",
    "# Create list from filter object result: res_list\n",
    "res_list = list(result)\n",
    "\n",
    "# Print all retweets in res_list\n",
    "for tweet in res_list:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "\n",
    "    # Add try block\n",
    "    try:\n",
    "        # Extract column from DataFrame: col\n",
    "        col = df[col_name]\n",
    "        \n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in col:\n",
    "    \n",
    "            # If entry is in cols_count, add 1\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "    \n",
    "        # Return the cols_count dictionary\n",
    "        return cols_count\n",
    "\n",
    "    # Add except block\n",
    "    except:\n",
    "        print('The DataFrame does not have a ' + col_name + ' column.')\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Print result1\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(df, col_name='lang'):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Raise a ValueError if col_name is NOT in DataFrame\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError('The DataFrame does not have a ' + col_name + ' column.')\n",
    "\n",
    "    # Initialize an empty dictionary: cols_count\n",
    "    cols_count = {}\n",
    "    \n",
    "    # Extract column from DataFrame: col\n",
    "    col = df[col_name]\n",
    "    \n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in col:\n",
    "\n",
    "        # If entry is in cols_count, add 1\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "            # Else add the entry to cols_count, set the value to 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "        \n",
    "        # Return the cols_count dictionary\n",
    "    return cols_count\n",
    "\n",
    "# Call count_entries(): result1\n",
    "result1 = count_entries(tweets_df, 'lang')\n",
    "\n",
    "# Print result1\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterators vs. Iterables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay garrick\n",
      "barry allen\n",
      "wally west\n",
      "bart allen\n",
      "jay garrick\n",
      "barry allen\n",
      "wally west\n",
      "bart allen\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: flash\n",
    "flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']\n",
    "\n",
    "# Print each list item in flash using a for loop\n",
    "for person in flash:\n",
    "    print(person)\n",
    "\n",
    "\n",
    "# Create an iterator for flash: superhero\n",
    "superhero = iter(flash)\n",
    "\n",
    "# Print each item from the iterator\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator for range(3): small_value\n",
    "small_value = iter(range(3))\n",
    "\n",
    "# Print the values in small_value\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "print(next(small_value))\n",
    "\n",
    "# Loop over range(3) and print the values\n",
    "for num in range(3):\n",
    "    print(num)\n",
    "\n",
    "\n",
    "# Create an iterator for range(10 ** 100): googol\n",
    "googol = iter(range(10 ** 100))\n",
    "\n",
    "# Print the first 5 values from googol\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n",
    "print(next(googol))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterators as function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(10, 21)\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "# Create a range object: values\n",
    "values = range(10,21)\n",
    "\n",
    "# Print the range object\n",
    "print(values)\n",
    "\n",
    "# Create a list of integers: values_list\n",
    "values_list = list(values)\n",
    "\n",
    "# Print values_list\n",
    "print(values_list)\n",
    "\n",
    "# Get the sum of values: values_sum\n",
    "values_sum = sum(values)\n",
    "\n",
    "# Print values_sum\n",
    "print(values_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]\n",
      "0 charles xavier\n",
      "1 bobby drake\n",
      "2 kurt wagner\n",
      "3 max eisenhardt\n",
      "4 kitty pryde\n",
      "1 charles xavier\n",
      "2 bobby drake\n",
      "3 kurt wagner\n",
      "4 max eisenhardt\n",
      "5 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: mutants\n",
    "mutants = ['charles xavier', \n",
    "            'bobby drake', \n",
    "            'kurt wagner', \n",
    "            'max eisenhardt', \n",
    "            'kitty pryde']\n",
    "\n",
    "# Create a list of tuples: mutant_list\n",
    "mutant_list = list((enumerate(mutants)))\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_list)\n",
    "\n",
    "# Unpack and print the tuple pairs\n",
    "for index1, value1 in enumerate(mutants):\n",
    "    print(index1, value1)\n",
    "\n",
    "# Change the start index\n",
    "for index1, value1 in enumerate(mutants, start=1):\n",
    "    print(index1, value1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000001BB65DE7DC0>\n",
      "[('charles xavier', 'prof x', 'telepathy'), ('bobby drake', 'iceman', 'thermokinesis'), ('kurt wagner', 'nightcrawler', 'teleportation'), ('max eisenhardt', 'magneto', 'magnetokinesis'), ('kitty pryde', 'shadowcat', 'intangibility')]\n",
      "charles xavier prof x telepathy\n",
      "bobby drake iceman thermokinesis\n",
      "kurt wagner nightcrawler teleportation\n",
      "max eisenhardt magneto magnetokinesis\n",
      "kitty pryde shadowcat intangibility\n"
     ]
    }
   ],
   "source": [
    "aliases= ['prof x', 'iceman', 'nightcrawler', 'magneto', 'shadowcat']\n",
    "powers = ['telepathy', 'thermokinesis', 'teleportation', 'magnetokinesis', 'intangibility']\n",
    "# Create a zip object using the three lists: mutant_zip\n",
    "mutant_zip = zip(mutants, aliases, powers) #returns a map object as the ouput\n",
    "\n",
    "# Print the zip object\n",
    "print(mutant_zip) \n",
    "\n",
    "# Create a list of tuples: mutant_data\n",
    "mutant_data = list(zip(mutants, aliases, powers)) #returns a lists of tuples.\n",
    "\n",
    "# Print the list of tuples\n",
    "print(mutant_data)\n",
    "\n",
    "# Unpack the zip object and print the tuple values\n",
    "for value1, value2, value3 in mutant_zip: #goes over the mutant_zip zip object and unpacks values\n",
    "    print(value1, value2, value3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using * and zip to 'unzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('charles xavier', 'telepathy') ('bobby drake', 'thermokinesis') ('kurt wagner', 'teleportation') ('max eisenhardt', 'magnetokinesis') ('kitty pryde', 'intangibility')\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Create a zip object from mutants and powers: z1\n",
    "z1 = zip(mutants, powers)\n",
    "\n",
    "# Print the tuples in z1 by unpacking with *\n",
    "print(*z1)\n",
    "\n",
    "# Re-create a zip object from mutants and powers: z1\n",
    "z1 = zip(mutants, powers)\n",
    "\n",
    "# 'Unzip' the tuples in z1 by unpacking with * and zip(): result1, result2\n",
    "result1, result2 = zip(*z1)\n",
    "\n",
    "# Check if unpacked tuples are equivalent to original tuples\n",
    "print(result1 == mutants)\n",
    "print(result2 == powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing large amounts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "# Iterate over the file chunk by chunk\n",
    "for chunk in pd.read_csv('tweets.csv', chunksize= 10):\n",
    "\n",
    "    # Iterate over the column in DataFrame\n",
    "    for entry in chunk['lang']:\n",
    "        if entry in counts_dict.keys():\n",
    "            counts_dict[entry] += 1\n",
    "        else:\n",
    "            counts_dict[entry] = 1\n",
    "\n",
    "# Print the populated dictionary\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information for large amounts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "# Define count_entries()\n",
    "def count_entries(csv_file, c_size, colname):\n",
    "    \"\"\"Return a dictionary with counts of\n",
    "    occurrences as value for each key.\"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Iterate over the file chunk by chunk\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=c_size):\n",
    "\n",
    "        # Iterate over the column in DataFrame\n",
    "        for entry in chunk[colname]:\n",
    "            if entry in counts_dict.keys():\n",
    "                counts_dict[entry] += 1\n",
    "            else:\n",
    "                counts_dict[entry] = 1\n",
    "\n",
    "    # Return counts_dict\n",
    "    return counts_dict\n",
    "\n",
    "# Call count_entries(): result_counts\n",
    "result_counts = count_entries('tweets.csv', 10,'lang')\n",
    "\n",
    "# Print result_counts\n",
    "print(result_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehensions\n",
    "* [output expression for iterator variable in iterable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'c', 'c', 't', 'w']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctor = ['house', 'cuddy', 'chase', 'thirteen', 'wilson']\n",
    "[doc[0] for doc in doctor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# Create list comprehension: squares\n",
    "squares = [i ** 2 for i in range(0,10)]\n",
    "print(squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested list comprehensions\n",
    "* [[output expression] for iterator variable in iterable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create a 5 x 5 matrix using a list of lists: matrix\n",
    "matrix = [[col for col in range(0,5)] for row in range(0,5)]\n",
    "\n",
    "# Print the matrix\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using conditionals in the iterable in list comprehensions\n",
    "* [ output expression for iterator variable in iterable if predicate expression ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'legolas', 'boromir']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using conditionals on the output expressions in list comprehensions\n",
    "* [ output expression if condition else result for iterator variable in iterable if predicate expression ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'samwise', '', 'aragorn', 'legolas', 'boromir', '']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create list comprehension: new_fellowship\n",
    "new_fellowship = [member if len(member) >= 7 else member.replace(member,\"\") for member in fellowship]\n",
    "\n",
    "# Print the new list\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dict comprehensions\n",
    "*  {key: value for var in iterable}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: -1, 2: -2, 3: -3, 4: -4, 5: -5, 6: -6, 7: -7, 8: -8}\n"
     ]
    }
   ],
   "source": [
    "pos_neg = {num: -num for num in range(9)}\n",
    "print(pos_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frodo': 5, 'samwise': 7, 'merry': 5, 'aragorn': 7, 'legolas': 7, 'boromir': 7, 'gimli': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: fellowship\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# Create dict comprehension: new_fellowship\n",
    "new_fellowship = {member: len(member) for member in fellowship}\n",
    "\n",
    "# Print the new dictionary\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehensions vs. generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of strings\n",
    "fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']\n",
    "\n",
    "# List comprehension\n",
    "fellow1 = [member for member in fellowship if len(member) >= 7]\n",
    "\n",
    "# Generator expression\n",
    "fellow2 = (member for member in fellowship if len(member) >= 7) #every time an iterable object is iterated the result is exhausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fellowship))\n",
    "print(type(fellow1))\n",
    "print(type(fellow2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratin over an iterable\n",
    "* iterable objects such as maps zips and generators can be unpacked this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samwise\n",
      "aragorn\n",
      "legolas\n",
      "boromir\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(list(fellow2)) \n",
    "#print(dict(fellow2))\n",
    "\n",
    "print(next(fellow2))\n",
    "\n",
    "for x in fellow2:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the output in generator expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings: lannister\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Create a generator object: lengths\n",
    "lengths = (len(person) for person in lannister)\n",
    "\n",
    "# Iterate over and print the values in lengths\n",
    "for value in lengths:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Create a list of strings\n",
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "# Define generator function get_lengths\n",
    "def get_lengths(input_list):\n",
    "    \"\"\"Generator function that yields the\n",
    "    length of the strings in input_list.\"\"\"\n",
    "\n",
    "    # Yield the length of a string\n",
    "    for person in input_list:\n",
    "        yield len(person)\n",
    "\n",
    "# Print the values generated by get_lengths()\n",
    "for value in get_lengths(lannister):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehensions for time-stamped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at'] #Pandas series\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional list comprehensions for time-stamped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = tweets['created_at']\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional list comprehensions for time-stamped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "# Extract the created_at column from df: tweet_time\n",
    "tweet_time = df['created_at']\n",
    "\n",
    "# Extract the clock time: tweet_clock_time\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
    "\n",
    "# Print the extracted times\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_vals = ['Arab World','ARB','Adolescent fertility rate (births per 1,000 women ages 15-19)','SP.ADO.TFRT','1960','133.56090740552298']\n",
    "feature_names = ['CountryName','CountryCode','IndicatorName','IndicatorCode','Year','Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Zip lists: zipped_lists\n",
    "zipped_lists = zip(feature_names, row_vals)\n",
    "\n",
    "# Create a dictionary: rs_dict\n",
    "rs_dict = dict(zipped_lists)\n",
    "\n",
    "# Print the dictionary\n",
    "print(rs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a function to help you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "# Define lists2dict()\n",
    "def lists2dict(list1, list2):\n",
    "    \"\"\"Return a dictionary where list1 provides\n",
    "    the keys and list2 provides the values.\"\"\"\n",
    "\n",
    "    # Zip lists: zipped_lists\n",
    "    zipped_lists = zip(list1, list2)\n",
    "\n",
    "    # Create a dictionary: rs_dict\n",
    "    rs_dict = dict(zipped_lists)\n",
    "\n",
    "    # Return the dictionary\n",
    "    return rs_dict\n",
    "\n",
    "# Call lists2dict: rs_fxn\n",
    "rs_fxn = lists2dict(feature_names, row_vals)\n",
    "\n",
    "# Print rs_fxn\n",
    "print(rs_fxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arab World\n",
      "ARB\n",
      "{'CountryName': 'A', 'CountryCode': 'r', 'IndicatorName': 'a', 'IndicatorCode': 'b', 'Year': ' ', 'Value': 'W'}\n",
      "{'CountryName': 'A', 'CountryCode': 'R', 'IndicatorName': 'B'}\n"
     ]
    }
   ],
   "source": [
    "# Print the first two lists in row_lists\n",
    "print(row_vals[0])\n",
    "print(row_vals[1])\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_vals]\n",
    "\n",
    "# Print the first two dictionaries in list_of_dicts\n",
    "print(list_of_dicts[0])\n",
    "print(list_of_dicts[1])\n",
    "#print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning this all into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CountryName CountryCode IndicatorName IndicatorCode Year Value\n",
      "0           A           r             a             b          W\n",
      "1           A           R             B           NaN  NaN   NaN\n",
      "2           A           d             o             l    e     s\n",
      "3           S           P             .             A    D     O\n",
      "4           1           9             6             0  NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_vals]\n",
    "\n",
    "# Turn list of dicts into a DataFrame: df\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arab World': 5, 'Caribbean small states': 5, 'Central Europe and the Baltics': 5, 'East Asia & Pacific (all income levels)': 5, 'East Asia & Pacific (developing only)': 5, 'Euro area': 5, 'Europe & Central Asia (all income levels)': 5, 'Europe & Central Asia (developing only)': 5, 'European Union': 5, 'Fragile and conflict affected situations': 5, 'Heavily indebted poor countries (HIPC)': 5, 'High income': 5, 'High income: nonOECD': 5, 'High income: OECD': 5, 'Latin America & Caribbean (all income levels)': 5, 'Latin America & Caribbean (developing only)': 5, 'Least developed countries: UN classification': 5, 'Low & middle income': 5, 'Low income': 5, 'Lower middle income': 5, 'Middle East & North Africa (all income levels)': 5, 'Middle East & North Africa (developing only)': 5, 'Middle income': 5, 'North America': 5, 'OECD members': 5, 'Other small states': 5, 'Pacific island small states': 5, 'Small states': 5, 'South Asia': 5, 'Sub-Saharan Africa (all income levels)': 5, 'Sub-Saharan Africa (developing only)': 5, 'Upper middle income': 5, 'World': 4, 'Afghanistan': 4, 'Albania': 4, 'Algeria': 4, 'American Samoa': 4, 'Andorra': 4, 'Angola': 4, 'Antigua and Barbuda': 4, 'Argentina': 4, 'Armenia': 4, 'Aruba': 4, 'Australia': 4, 'Austria': 4, 'Azerbaijan': 4, '\"Bahamas': 4, 'Bahrain': 4, 'Bangladesh': 4, 'Barbados': 4, 'Belarus': 4, 'Belgium': 4, 'Belize': 4, 'Benin': 4, 'Bermuda': 4, 'Bhutan': 4, 'Bolivia': 4, 'Bosnia and Herzegovina': 4, 'Botswana': 4, 'Brazil': 4, 'Brunei Darussalam': 4, 'Bulgaria': 4, 'Burkina Faso': 4, 'Burundi': 4, 'Cabo Verde': 4, 'Cambodia': 4, 'Cameroon': 4, 'Canada': 4, 'Cayman Islands': 4, 'Central African Republic': 4, 'Chad': 4, 'Channel Islands': 4, 'Chile': 4, 'China': 4, 'Colombia': 4, 'Comoros': 4, '\"Congo': 8, 'Costa Rica': 4, \"Cote d'Ivoire\": 4, 'Croatia': 4, 'Cuba': 4, 'Curacao': 4, 'Cyprus': 4, 'Czech Republic': 4, 'Denmark': 4, 'Djibouti': 4, 'Dominica': 4, 'Dominican Republic': 4, 'Ecuador': 4, '\"Egypt': 4, 'El Salvador': 4, 'Equatorial Guinea': 4, 'Eritrea': 4, 'Estonia': 4, 'Ethiopia': 4, 'Faeroe Islands': 4, 'Fiji': 4, 'Finland': 4, 'France': 4, 'French Polynesia': 4, 'Gabon': 4, '\"Gambia': 4, 'Georgia': 4, 'Germany': 4, 'Ghana': 4, 'Greece': 4, 'Greenland': 4, 'Grenada': 4, 'Guam': 4, 'Guatemala': 4, 'Guinea': 4, 'Guinea-Bissau': 4, 'Guyana': 4, 'Haiti': 4, 'Honduras': 4, '\"Hong Kong SAR': 4, 'Hungary': 4, 'Iceland': 4, 'India': 4, 'Indonesia': 4, '\"Iran': 4, 'Iraq': 4, 'Ireland': 4, 'Isle of Man': 4, 'Israel': 4, 'Italy': 4, 'Jamaica': 4, 'Japan': 4, 'Jordan': 4, 'Kazakhstan': 4, 'Kenya': 4, 'Kiribati': 4, '\"Korea': 8, 'Kuwait': 4, 'Kyrgyz Republic': 4, 'Lao PDR': 4, 'Latvia': 4, 'Lebanon': 4, 'Lesotho': 4, 'Liberia': 4, 'Libya': 4, 'Liechtenstein': 4, 'Lithuania': 4, 'Luxembourg': 4, '\"Macao SAR': 4, '\"Macedonia': 4, 'Madagascar': 4, 'Malawi': 4, 'Malaysia': 4, 'Maldives': 4, 'Mali': 4, 'Malta': 4, 'Marshall Islands': 4, 'Mauritania': 4, 'Mauritius': 4, 'Mexico': 4, '\"Micronesia': 4, 'Moldova': 4, 'Monaco': 4, 'Mongolia': 4, 'Montenegro': 4, 'Morocco': 4, 'Mozambique': 4, 'Myanmar': 4, 'Namibia': 4, 'Nepal': 4, 'Netherlands': 4, 'New Caledonia': 4, 'New Zealand': 4, 'Nicaragua': 4, 'Niger': 4, 'Nigeria': 4, 'Northern Mariana Islands': 4, 'Norway': 4, 'Oman': 4, 'Pakistan': 4, 'Palau': 4, 'Panama': 4, 'Papua New Guinea': 4, 'Paraguay': 4, 'Peru': 4, 'Philippines': 4, 'Poland': 4, 'Portugal': 4, 'Puerto Rico': 4, 'Qatar': 4, 'Romania': 4, 'Russian Federation': 4, 'Rwanda': 4, 'Samoa': 4, 'San Marino': 4, 'Sao Tome and Principe': 4, 'Saudi Arabia': 4, 'Senegal': 4, 'Seychelles': 4, 'Sierra Leone': 4, 'Singapore': 4, 'Slovak Republic': 4, 'Slovenia': 4, 'Solomon Islands': 4, 'Somalia': 4, 'South Africa': 4, 'South Sudan': 4, 'Spain': 4, 'Sri Lanka': 4, 'St. Kitts and Nevis': 4, 'St. Lucia': 4, 'St. Vincent and the Grenadines': 4, 'Sudan': 4, 'Suriname': 4, 'Swaziland': 4, 'Sweden': 4, 'Switzerland': 4, 'Syrian Arab Republic': 4, 'Tajikistan': 4, 'Tanzania': 4, 'Thailand': 4, 'Timor-Leste': 4, 'Togo': 4, 'Tonga': 4, 'Trinidad and Tobago': 4, 'Tunisia': 4, 'Turkey': 4, 'Turkmenistan': 4, 'Turks and Caicos Islands': 4, 'Tuvalu': 4, 'Uganda': 4, 'Ukraine': 4, 'United Arab Emirates': 4, 'United Kingdom': 4, 'United States': 4, 'Uruguay': 4, 'Uzbekistan': 4, 'Vanuatu': 4, '\"Venezuela': 4, 'Vietnam': 4, 'Virgin Islands (U.S.)': 4, '\"Yemen': 4, 'Zambia': 4, 'Zimbabwe': 4}\n"
     ]
    }
   ],
   "source": [
    "# Open a connection to the file\n",
    "with open('world_ind_pop_data.csv') as file:\n",
    "\n",
    "    # Skip the column names\n",
    "    file.readline()\n",
    "\n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Process only the first 1000 rows\n",
    "    for j in range(0,1000):\n",
    "\n",
    "        # Split the current line into a list: line\n",
    "        line = file.readline().split(',')\n",
    "\n",
    "        # Get the value for the first column: first_col\n",
    "        first_col = line[0]\n",
    "\n",
    "        # If the column value is in the dict, increment its value\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "\n",
    "        # Else, add to the dict and set value to 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a generator to load data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example:\n",
    "def num_sequence(n):\n",
    "    \"\"\"Generate values from 0 to n\"\"\"\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        yield i\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryName,CountryCode,Year,Total Population,Urban population (% of total)\n",
      "\n",
      "Arab World,ARB,1960,92495902.0,31.285384211605397\n",
      "\n",
      "Caribbean small states,CSS,1960,4190810.0,31.5974898513652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define read_large_file()\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "\n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "\n",
    "        # Read a line from the file: data\n",
    "        data = file_object.readline()\n",
    "\n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        # Yield the line of data\n",
    "        yield data\n",
    "        #end of generator.\n",
    "# Open a connection to the file\n",
    "with open('world_ind_pop_data.csv') as file:\n",
    "\n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = read_large_file(file)\n",
    "\n",
    "    # Print the first three lines of the file\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a generator to load data in chunks (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 1, 'Arab World': 55, 'Caribbean small states': 55, 'Central Europe and the Baltics': 55, 'East Asia & Pacific (all income levels)': 55, 'East Asia & Pacific (developing only)': 55, 'Euro area': 55, 'Europe & Central Asia (all income levels)': 55, 'Europe & Central Asia (developing only)': 55, 'European Union': 55, 'Fragile and conflict affected situations': 55, 'Heavily indebted poor countries (HIPC)': 55, 'High income': 55, 'High income: nonOECD': 55, 'High income: OECD': 55, 'Latin America & Caribbean (all income levels)': 55, 'Latin America & Caribbean (developing only)': 55, 'Least developed countries: UN classification': 55, 'Low & middle income': 55, 'Low income': 55, 'Lower middle income': 55, 'Middle East & North Africa (all income levels)': 55, 'Middle East & North Africa (developing only)': 55, 'Middle income': 55, 'North America': 55, 'OECD members': 55, 'Other small states': 55, 'Pacific island small states': 55, 'Small states': 55, 'South Asia': 55, 'Sub-Saharan Africa (all income levels)': 55, 'Sub-Saharan Africa (developing only)': 55, 'Upper middle income': 55, 'World': 55, 'Afghanistan': 55, 'Albania': 55, 'Algeria': 55, 'American Samoa': 55, 'Andorra': 55, 'Angola': 55, 'Antigua and Barbuda': 55, 'Argentina': 55, 'Armenia': 55, 'Aruba': 55, 'Australia': 55, 'Austria': 55, 'Azerbaijan': 55, '\"Bahamas': 55, 'Bahrain': 55, 'Bangladesh': 55, 'Barbados': 55, 'Belarus': 55, 'Belgium': 55, 'Belize': 55, 'Benin': 55, 'Bermuda': 55, 'Bhutan': 55, 'Bolivia': 55, 'Bosnia and Herzegovina': 55, 'Botswana': 55, 'Brazil': 55, 'Brunei Darussalam': 55, 'Bulgaria': 55, 'Burkina Faso': 55, 'Burundi': 55, 'Cabo Verde': 55, 'Cambodia': 55, 'Cameroon': 55, 'Canada': 55, 'Cayman Islands': 55, 'Central African Republic': 55, 'Chad': 55, 'Channel Islands': 55, 'Chile': 55, 'China': 55, 'Colombia': 55, 'Comoros': 55, '\"Congo': 110, 'Costa Rica': 55, \"Cote d'Ivoire\": 55, 'Croatia': 55, 'Cuba': 55, 'Curacao': 55, 'Cyprus': 55, 'Czech Republic': 55, 'Denmark': 55, 'Djibouti': 55, 'Dominica': 55, 'Dominican Republic': 55, 'Ecuador': 55, '\"Egypt': 55, 'El Salvador': 55, 'Equatorial Guinea': 55, 'Eritrea': 55, 'Estonia': 55, 'Ethiopia': 55, 'Faeroe Islands': 55, 'Fiji': 55, 'Finland': 55, 'France': 55, 'French Polynesia': 55, 'Gabon': 55, '\"Gambia': 55, 'Georgia': 55, 'Germany': 55, 'Ghana': 55, 'Greece': 55, 'Greenland': 55, 'Grenada': 55, 'Guam': 55, 'Guatemala': 55, 'Guinea': 55, 'Guinea-Bissau': 55, 'Guyana': 55, 'Haiti': 55, 'Honduras': 55, '\"Hong Kong SAR': 55, 'Hungary': 55, 'Iceland': 55, 'India': 55, 'Indonesia': 55, '\"Iran': 55, 'Iraq': 55, 'Ireland': 55, 'Isle of Man': 55, 'Israel': 55, 'Italy': 55, 'Jamaica': 55, 'Japan': 55, 'Jordan': 55, 'Kazakhstan': 55, 'Kenya': 55, 'Kiribati': 55, '\"Korea': 110, 'Kuwait': 52, 'Kyrgyz Republic': 55, 'Lao PDR': 55, 'Latvia': 55, 'Lebanon': 55, 'Lesotho': 55, 'Liberia': 55, 'Libya': 55, 'Liechtenstein': 55, 'Lithuania': 55, 'Luxembourg': 55, '\"Macao SAR': 55, '\"Macedonia': 55, 'Madagascar': 55, 'Malawi': 55, 'Malaysia': 55, 'Maldives': 55, 'Mali': 55, 'Malta': 55, 'Marshall Islands': 55, 'Mauritania': 55, 'Mauritius': 55, 'Mexico': 55, '\"Micronesia': 55, 'Moldova': 55, 'Monaco': 55, 'Mongolia': 55, 'Montenegro': 55, 'Morocco': 55, 'Mozambique': 55, 'Myanmar': 55, 'Namibia': 55, 'Nepal': 55, 'Netherlands': 55, 'New Caledonia': 55, 'New Zealand': 55, 'Nicaragua': 55, 'Niger': 55, 'Nigeria': 55, 'Northern Mariana Islands': 55, 'Norway': 55, 'Oman': 55, 'Pakistan': 55, 'Palau': 55, 'Panama': 55, 'Papua New Guinea': 55, 'Paraguay': 55, 'Peru': 55, 'Philippines': 55, 'Poland': 55, 'Portugal': 55, 'Puerto Rico': 55, 'Qatar': 55, 'Romania': 55, 'Russian Federation': 55, 'Rwanda': 55, 'Samoa': 55, 'San Marino': 55, 'Sao Tome and Principe': 55, 'Saudi Arabia': 55, 'Senegal': 55, 'Seychelles': 55, 'Sierra Leone': 55, 'Singapore': 55, 'Slovak Republic': 55, 'Slovenia': 55, 'Solomon Islands': 55, 'Somalia': 55, 'South Africa': 55, 'South Sudan': 55, 'Spain': 55, 'Sri Lanka': 55, 'St. Kitts and Nevis': 55, 'St. Lucia': 55, 'St. Vincent and the Grenadines': 55, 'Sudan': 55, 'Suriname': 55, 'Swaziland': 55, 'Sweden': 55, 'Switzerland': 55, 'Syrian Arab Republic': 55, 'Tajikistan': 55, 'Tanzania': 55, 'Thailand': 55, 'Timor-Leste': 55, 'Togo': 55, 'Tonga': 55, 'Trinidad and Tobago': 55, 'Tunisia': 55, 'Turkey': 55, 'Turkmenistan': 55, 'Turks and Caicos Islands': 55, 'Tuvalu': 55, 'Uganda': 55, 'Ukraine': 55, 'United Arab Emirates': 55, 'United Kingdom': 55, 'United States': 55, 'Uruguay': 55, 'Uzbekistan': 55, 'Vanuatu': 55, '\"Venezuela': 55, 'Vietnam': 55, 'Virgin Islands (U.S.)': 55, '\"Yemen': 55, 'Zambia': 55, 'Zimbabwe': 55, 'Serbia': 25, 'West Bank and Gaza': 25, 'Sint Maarten (Dutch part)': 17}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('world_ind_pop_data.csv') as file:\n",
    "\n",
    "    # Iterate over the generator from read_large_file()\n",
    "    for line in read_large_file(file):\n",
    "\n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print            \n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing an iterator to load data in chunks (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 CountryName CountryCode  Year  \\\n",
      "0                                 Arab World         ARB  1960   \n",
      "1                     Caribbean small states         CSS  1960   \n",
      "2             Central Europe and the Baltics         CEB  1960   \n",
      "3    East Asia & Pacific (all income levels)         EAS  1960   \n",
      "4      East Asia & Pacific (developing only)         EAP  1960   \n",
      "5                                  Euro area         EMU  1960   \n",
      "6  Europe & Central Asia (all income levels)         ECS  1960   \n",
      "7    Europe & Central Asia (developing only)         ECA  1960   \n",
      "8                             European Union         EUU  1960   \n",
      "9   Fragile and conflict affected situations         FCS  1960   \n",
      "\n",
      "   Total Population  Urban population (% of total)  \n",
      "0      9.249590e+07                      31.285384  \n",
      "1      4.190810e+06                      31.597490  \n",
      "2      9.140158e+07                      44.507921  \n",
      "3      1.042475e+09                      22.471132  \n",
      "4      8.964930e+08                      16.917679  \n",
      "5      2.653965e+08                      62.096947  \n",
      "6      6.674890e+08                      55.378977  \n",
      "7      1.553174e+08                      38.066129  \n",
      "8      4.094985e+08                      61.212898  \n",
      "9      1.203546e+08                      17.891972  \n",
      "                                      CountryName CountryCode  Year  \\\n",
      "10         Heavily indebted poor countries (HIPC)         HPC  1960   \n",
      "11                                    High income         HIC  1960   \n",
      "12                           High income: nonOECD         NOC  1960   \n",
      "13                              High income: OECD         OEC  1960   \n",
      "14  Latin America & Caribbean (all income levels)         LCN  1960   \n",
      "15    Latin America & Caribbean (developing only)         LAC  1960   \n",
      "16   Least developed countries: UN classification         LDC  1960   \n",
      "17                            Low & middle income         LMY  1960   \n",
      "18                                     Low income         LIC  1960   \n",
      "19                            Lower middle income         LMC  1960   \n",
      "\n",
      "    Total Population  Urban population (% of total)  \n",
      "10      1.624912e+08                      12.236046  \n",
      "11      9.075975e+08                      62.680332  \n",
      "12      1.866767e+08                      56.107863  \n",
      "13      7.209208e+08                      64.285435  \n",
      "14      2.205642e+08                      49.284688  \n",
      "15      1.776822e+08                      44.863308  \n",
      "16      2.410728e+08                       9.616261  \n",
      "17      2.127373e+09                      21.272894  \n",
      "18      1.571884e+08                      11.498396  \n",
      "19      9.429116e+08                      19.810513  \n"
     ]
    }
   ],
   "source": [
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize reader object: df_reader\n",
    "df_reader = pd.read_csv('world_ind_pop_data.csv', chunksize=10)\n",
    "\n",
    "# Print two chunks\n",
    "print(next(df_reader))\n",
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing an iterator to load data in chunks (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               CountryName CountryCode  Year  \\\n",
      "0                               Arab World         ARB  1960   \n",
      "1                   Caribbean small states         CSS  1960   \n",
      "2           Central Europe and the Baltics         CEB  1960   \n",
      "3  East Asia & Pacific (all income levels)         EAS  1960   \n",
      "4    East Asia & Pacific (developing only)         EAP  1960   \n",
      "\n",
      "   Total Population  Urban population (% of total)  \n",
      "0      9.249590e+07                      31.285384  \n",
      "1      4.190810e+06                      31.597490  \n",
      "2      9.140158e+07                      44.507921  \n",
      "3      1.042475e+09                      22.471132  \n",
      "4      8.964930e+08                      16.917679  \n",
      "[(91401583.0, 44.5079211390026), (92237118.0, 45.206665319194), (93014890.0, 45.866564696018), (93845749.0, 46.5340927663649), (94722599.0, 47.2087429803526)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('world_ind_pop_data.csv', chunksize=1000)\n",
    "\n",
    "# Get the first DataFrame chunk: df_urb_pop\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "\n",
    "# Check out the head of the DataFrame\n",
    "print(df_urb_pop.head())\n",
    "\n",
    "# Check out specific country: df_pop_ceb\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "# Zip DataFrame columns of interest: pops\n",
    "pops = zip(df_pop_ceb['Total Population'], df_pop_ceb['Urban population (% of total)'])\n",
    "\n",
    "# Turn zip object into list: pops_list\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Print pops_list\n",
    "print(pops_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing an iterator to load data in chunks (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luispcode\\AppData\\Local\\Temp\\ipykernel_16760\\1425324661.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pop_ceb['Total Urban Population'] = [(int(pop * perc *0.01)) for pop,perc in pops_list]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code from previous exercise\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "urb_pop_reader = pd.read_csv('world_ind_pop_data.csv', chunksize=1000)\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "pops = zip(df_pop_ceb['Total Population'], \n",
    "           df_pop_ceb['Urban population (% of total)'])\n",
    "pops_list = list(pops)\n",
    "\n",
    "#Use list comprehension to create new DataFrame column 'Total Urban Population'\n",
    "df_pop_ceb['Total Urban Population'] = [(int(pop * perc *0.01)) for pop,perc in pops_list]\n",
    "\n",
    "\n",
    "# Plot urban population data\n",
    "\n",
    "df_pop_ceb.plot(kind='bar', x='Year', y='Total Urban Population')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1ec09b0d1bbb5cdb2714cd3190b8798aa073293e786692a18afb00e186dc573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
